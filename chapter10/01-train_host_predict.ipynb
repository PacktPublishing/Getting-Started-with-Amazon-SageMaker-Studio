{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'sagemaker-studio-book/chapter10/abalone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import uuid\n",
    "from time import sleep, gmtime, strftime\n",
    "from threading import Thread\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from botocore.exceptions import ClientError\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "from sagemaker.model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Sex', 'Length', 'Diameter', 'Height', 'WholeWeight', 'ShuckedWeight', 'VisceraWeight', 'ShellWeight', 'Rings']\n",
    "df=pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data', names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df.copy()\n",
    "df_processed['Rings']=df_processed['Rings'].astype(float)\n",
    "df_processed['Sex'] = df_processed['Sex'].replace(to_replace=['M', 'F', 'I'], value=[2., 1., 0.])\n",
    "columns=['Rings', 'Sex', 'Length', 'Diameter', 'Height', 'WholeWeight', 'ShuckedWeight', 'VisceraWeight', 'ShellWeight']\n",
    "df_processed = df_processed[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_build, df_test = train_test_split(df_processed, test_size=0.1, random_state=42, \n",
    "                                     shuffle=True, stratify=df_processed['Sex'])\n",
    "df_train, df_val = train_test_split(df_build, test_size=1/9., random_state=42, \n",
    "                                    shuffle=True, stratify=df_build['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_no_target = ['Sex', 'Length', 'Diameter', 'Height', 'WholeWeight', 'ShuckedWeight', 'VisceraWeight', 'ShellWeight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('abalone', exist_ok=True)\n",
    "df_train.to_csv('./abalone/abalone_train.csv', index=False)\n",
    "df_val.to_csv('./abalone/abalone_val.csv', index=False)\n",
    "df_test.to_csv('./abalone/abalone_test.csv', index=False)\n",
    "# df_test[columns_no_target].to_csv('./abalone/abalone_test_no_target.csv', index=False, header=False)\n",
    "\n",
    "desired_s3_uri = f's3://{bucket}/{prefix}/data'\n",
    "train_data_s3 = sagemaker.s3.S3Uploader.upload(local_path='./abalone/abalone_train.csv',\n",
    "                                               desired_s3_uri=desired_s3_uri,\n",
    "                                               sagemaker_session=sess)\n",
    "val_data_s3 = sagemaker.s3.S3Uploader.upload(local_path='./abalone/abalone_val.csv',\n",
    "                                             desired_s3_uri=desired_s3_uri,\n",
    "                                             sagemaker_session=sess)\n",
    "test_data_s3 = sagemaker.s3.S3Uploader.upload(local_path='./abalone/abalone_test.csv',\n",
    "                                              desired_s3_uri=desired_s3_uri,\n",
    "                                              sagemaker_session=sess)\n",
    "# sagemaker.s3.S3Uploader.upload(local_path='abalone_test_no_target.csv',\n",
    "#                                desired_s3_uri=desired_s3_uri,\n",
    "#                                sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a ML model to predict `Rings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading from an existing training job\n",
    "exp_datetime = '2021-12-18-00-04-35'\n",
    "jobname = f'abalone-xgb-{exp_datetime}'\n",
    "xgb=sagemaker.estimator.Estimator.attach(jobname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image_uris.retrieve(region=region, framework='xgboost', version='1.3-1')\n",
    "\n",
    "exp_datetime = strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n",
    "jobname = f'abalone-xgb-{exp_datetime}'\n",
    "\n",
    "experiment_name = 'abalone-age-prediction'\n",
    "\n",
    "try:\n",
    "    experiment = Experiment.create(\n",
    "        experiment_name=experiment_name, \n",
    "        description='Predicting age for abalone based on physical measurements.')\n",
    "except ClientError as e:\n",
    "    print(f'{experiment_name} experiment already exists! Reusing the existing experiment.')\n",
    "    \n",
    "# Creating a new trial for the experiment\n",
    "exp_trial = Trial.create(experiment_name=experiment_name, \n",
    "                         trial_name=jobname)\n",
    "\n",
    "experiment_config={\n",
    "    'ExperimentName': experiment_name,\n",
    "    'TrialName': exp_trial.trial_name,\n",
    "    'TrialComponentDisplayName': 'Training'}\n",
    "\n",
    "train_instance_type = 'ml.m5.xlarge'\n",
    "train_instance_count = 1\n",
    "s3_output = f's3://{bucket}/{prefix}/abalone_data/training'\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(image,\n",
    "                                    role,\n",
    "                                    instance_count=train_instance_count,\n",
    "                                    instance_type=train_instance_type,\n",
    "                                    output_path=s3_output,\n",
    "                                    enable_sagemaker_metrics=True,\n",
    "                                    sagemaker_session=sess)\n",
    "\n",
    "xgb.set_hyperparameters(objective='reg:squarederror', num_round=20)\n",
    "\n",
    "train_input = sagemaker.inputs.TrainingInput(s3_data=train_data_s3, \n",
    "                                             content_type='csv')\n",
    "val_input = sagemaker.inputs.TrainingInput(s3_data=val_data_s3, \n",
    "                                           content_type='csv')\n",
    "data_channels={'train': train_input, 'validation': val_input}\n",
    "\n",
    "xgb.fit(inputs=data_channels, \n",
    "        job_name=jobname, \n",
    "        experiment_config=experiment_config, \n",
    "        wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model with data capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "exp_datetime = '2021-12-18-00-04-35'\n",
    "endpoint_name = f'abalone-xgb-{exp_datetime}-2'\n",
    "print(f'EndpointName: {endpoint_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##S3 prefixes\n",
    "data_capture_prefix = f'{prefix}/datacapture'\n",
    "s3_capture_upload_path = f's3://{bucket}/{data_capture_prefix}'\n",
    "\n",
    "# exp_datetime = strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n",
    "ground_truth_upload_path = f's3://{bucket}/{prefix}/ground-truth-data/{exp_datetime}'\n",
    "\n",
    "# reports_prefix = f'{prefix}/reports'\n",
    "# s3_report_path = f's3://{bucket}/{reports_prefix}'\n",
    "\n",
    "##Get the model monitor image\n",
    "# monitor_image_uri = image_uris.retrieve(framework='model-monitor', region=region)\n",
    "\n",
    "# print('Image URI:', monitor_image_uri)\n",
    "print(f'Capture path: {s3_capture_upload_path}')\n",
    "print(f'Ground truth path: {ground_truth_upload_path}')\n",
    "# print(f'Report path: {s3_report_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_capture_config = DataCaptureConfig(enable_capture=True, \n",
    "                                        sampling_percentage=100, \n",
    "                                        destination_s3_uri=s3_capture_upload_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint_name = f'abalone-xgb-{exp_datetime}'\n",
    "print(f'EndpointName: {endpoint_name}')\n",
    "\n",
    "predictor = xgb.deploy(initial_instance_count=1,\n",
    "                       instance_type='ml.m5.large',\n",
    "                       endpoint_name=endpoint_name,\n",
    "                       serializer=CSVSerializer(),\n",
    "                       data_capture_config=data_capture_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading from an existing endpoint\n",
    "predictor = Predictor(endpoint_name=endpoint_name, \n",
    "                      sagemaker_session=sess, \n",
    "                      serializer=CSVSerializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish a persistent load with randomness and ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_randomness(series, probability = 0.1):\n",
    "    random_rate=(np.random.rand(series.shape[0])<probability).astype(float)\n",
    "    sigma_scale=0.5\n",
    "    \n",
    "    new_series = series * np.random.normal(loc=1, scale=sigma_scale*random_rate, size=series.shape)\n",
    "    \n",
    "    if random_rate[0] != 1.:\n",
    "        # if random_rate for Sex (first cell in random_rate) is not 1,\n",
    "        # then assign a random value from [0,2].\n",
    "        new_series[0] = float(np.random.randint(0, 2))\n",
    "    else:\n",
    "        new_series[0] = series[0]\n",
    "\n",
    "    return new_series\n",
    "\n",
    "\n",
    "def drop_random(series, probability = 0.05):\n",
    "    random_rate=(np.random.rand(series.shape[0])<probability)\n",
    "    new_series = series.copy()\n",
    "    new_series[random_rate]=np.nan\n",
    "    \n",
    "    return new_series\n",
    "\n",
    "def convert_nparray_to_string(series):\n",
    "    new_series = ','.join([str(i) for i in series])\n",
    "    new_series = new_series.replace('nan', '')\n",
    "    \n",
    "    return new_series\n",
    "    \n",
    "def upload_ground_truth(records, ground_truth_upload_path, upload_time):\n",
    "    records_json = [json.dumps(r) for r in records]\n",
    "    data_to_upload = \"\\n\".join(records_json)\n",
    "    target_s3_uri = f\"{ground_truth_upload_path}/{upload_time:%Y/%m/%d/%H/%M%S}.jsonl\"\n",
    "    sagemaker.s3.S3Uploader.upload_string_as_file_body(data_to_upload, target_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_load_and_ground_truth():\n",
    "    gt_records=[]\n",
    "    for i, row in df_test.iterrows():\n",
    "        suffix = uuid.uuid1().hex\n",
    "        inference_id = f'{i}-{suffix}'\n",
    "        \n",
    "        gt = row['Rings']\n",
    "        data = row[columns_no_target].values\n",
    "#         print(inference_id, data)\n",
    "        new_data = drop_random(add_randomness(data))\n",
    "        new_data = convert_nparray_to_string(new_data)\n",
    "#         print(inference_id, new_data)\n",
    "        out = predictor.predict(data = new_data, inference_id = inference_id)\n",
    "#         print(inference_id, gt, out)\n",
    "\n",
    "        gt_data =  {\"groundTruthData\": {\n",
    "                            \"data\": str(gt), \n",
    "                            \"encoding\": \"CSV\",\n",
    "                        },\n",
    "                        \"eventMetadata\": {\n",
    "                            \"eventId\": inference_id,\n",
    "                        },\n",
    "                        \"eventVersion\": \"0\",\n",
    "                    }\n",
    "#         print(gt_data)\n",
    "        gt_records.append(gt_data)\n",
    "\n",
    "    upload_ground_truth(gt_records, ground_truth_upload_path, datetime.utcnow())\n",
    "    \n",
    "def generate_load_and_ground_truth_forever():\n",
    "    while True:\n",
    "        generate_load_and_ground_truth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_load_and_ground_truth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = Thread(target=generate_load_and_ground_truth_forever)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread.is_alive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obj_body(obj_key):\n",
    "    return s3_client.get_object(Bucket=bucket, Key=obj_key).get(\"Body\").read().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.Session().client(\"s3\")\n",
    "current_endpoint_capture_prefix = \"{}/{}\".format(data_capture_prefix, endpoint_name)\n",
    "result = s3_client.list_objects(Bucket=bucket, Prefix=current_endpoint_capture_prefix)\n",
    "capture_files = [capture_file.get(\"Key\") for capture_file in result.get(\"Contents\")]\n",
    "print(\"Found Capture Files:\")\n",
    "print(\"\\n \".join(capture_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_file = get_obj_body(capture_files[-1])\n",
    "print(json.dumps(json.loads(capture_file.split(\"\\n\")[-2]), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: tear down data quality baseline and schedule, setup another one with Rings in float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy over the training dataset to Amazon S3 (if you already have it in Amazon S3, you could reuse it)\n",
    "model_monitor_prefix = f'{prefix}/data-quality-output' # data-quality-output/baseline/\n",
    "baseline_results_prefix = f'{model_monitor_prefix}/baseline'\n",
    "\n",
    "baseline_data_uri = train_data_s3\n",
    "baseline_results_uri = f's3://{bucket}/{baseline_results_prefix}'\n",
    "\n",
    "s3_report_path = f's3://{bucket}/{model_monitor_prefix}/reports'\n",
    "\n",
    "print('Baseline data uri: {}'.format(baseline_data_uri))\n",
    "print('Baseline results uri: {}'.format(baseline_results_uri))\n",
    "print(f'Report path: {s3_report_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "\n",
    "my_default_monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=1,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")\n",
    "\n",
    "my_default_monitor.suggest_baseline(\n",
    "    baseline_dataset=train_data_s3,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=baseline_results_uri,\n",
    "    wait=False,\n",
    "    logs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import CronExpressionGenerator\n",
    "\n",
    "mon_schedule_name = f'abalone-data-monitor-schedule-{exp_datetime}-2'\n",
    "\n",
    "my_default_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=mon_schedule_name,\n",
    "    endpoint_input=predictor.endpoint,\n",
    "    # record_preprocessor_script=pre_processor_script,\n",
    "    # post_analytics_processor_script=s3_code_postprocessor_uri,\n",
    "    output_s3_uri=s3_report_path,\n",
    "    statistics=my_default_monitor.baseline_statistics(),\n",
    "    constraints=my_default_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_results_prefix = f'{prefix}/abalone_data/data-quality-output/baseline'\n",
    "result = s3_client.list_objects(Bucket=bucket, Prefix=baseline_results_prefix)\n",
    "report_files = [report_file.get(\"Key\") for report_file in result.get(\"Contents\")]\n",
    "print(\"Found Files:\")\n",
    "print(\"\\n \".join(report_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create model quality baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer, NumpySerializer\n",
    "from sagemaker.deserializers import NumpyDeserializer, PandasDeserializer, CSVDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_np = Predictor(endpoint_name=endpoint_name, \n",
    "                         sagemaker_session=sess,\n",
    "                         serializer=CSVSerializer(),\n",
    "                         deserializer=CSVDeserializer())\n",
    "pred=predictor_np.predict(df_val[columns_no_target].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_f = [float(i) for i in pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['Prediction']=pred_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[['Rings', 'Prediction']].to_csv('abalone_val_model_quality_baseline.csv', index=False)\n",
    "model_quality_baseline_s3 = sagemaker.s3.S3Uploader.upload(local_path='abalone_val_model_quality_baseline.csv',\n",
    "                                             desired_s3_uri=desired_s3_uri,\n",
    "                                             sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_monitor import ModelQualityMonitor\n",
    "from sagemaker.model_monitor import EndpointInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy over the training dataset to Amazon S3 (if you already have it in Amazon S3, you could reuse it)\n",
    "model_quality_monitor_prefix = f'{prefix}/model-quality-output' # data-quality-output/baseline/\n",
    "model_quality_baseline_results_prefix = f'{model_quality_monitor_prefix}/baseline'\n",
    "\n",
    "model_quality_baseline_results_uri = f's3://{bucket}/{model_quality_baseline_results_prefix}'\n",
    "\n",
    "model_quality_s3_report_path = f's3://{bucket}/{model_quality_monitor_prefix}/reports'\n",
    "\n",
    "print('Baseline data uri: {}'.format(model_quality_baseline_s3))\n",
    "print('Baseline results uri: {}'.format(model_quality_baseline_results_uri))\n",
    "print(f'Report path: {model_quality_s3_report_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model quality monitoring object\n",
    "my_model_quality_monitor = ModelQualityMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.xlarge',\n",
    "    volume_size_in_gb=1,\n",
    "    max_runtime_in_seconds=1800,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "# Execute the baseline suggestion job.\n",
    "# You will specify problem type, in this case Binary Classification, and provide other required attributes.\n",
    "my_model_quality_monitor.suggest_baseline(\n",
    "    baseline_dataset=model_quality_baseline_s3,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=model_quality_baseline_results_uri,\n",
    "    problem_type='Regression',\n",
    "    inference_attribute='Prediction',\n",
    "#     probability_attribute=\"probability\",\n",
    "    ground_truth_attribute='Rings',\n",
    "    wait=False,\n",
    "    logs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quality_baseline_results_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_schedule_name_2 = f'abalone-modelquality-monitor-schedule-{exp_datetime}-2'\n",
    "\n",
    "# Create an enpointInput\n",
    "endpointInput = EndpointInput(\n",
    "    endpoint_name=predictor.endpoint_name,\n",
    "    inference_attribute='0',\n",
    "    destination='/opt/ml/processing/input_data',\n",
    "    start_time_offset='-PT1H',\n",
    "    end_time_offset='-PT0H'\n",
    ")\n",
    "response = my_model_quality_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=mon_schedule_name_2,\n",
    "    endpoint_input=endpointInput,\n",
    "    output_s3_uri=model_quality_baseline_results_uri,\n",
    "    problem_type='Regression',\n",
    "    ground_truth_input=ground_truth_upload_path,\n",
    "    constraints=my_model_quality_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_quality_monitor.baseline_statistics().body_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_quality_monitor.suggested_constraints().body_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model bias monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.clarify import (\n",
    "    BiasConfig,\n",
    "    DataConfig,\n",
    "    ModelConfig,\n",
    "    ModelPredictedLabelConfig,\n",
    "    SHAPConfig,\n",
    ")\n",
    "from sagemaker.model_monitor import (\n",
    "    BiasAnalysisConfig,\n",
    "    CronExpressionGenerator,\n",
    "    DataCaptureConfig,\n",
    "    EndpointInput,\n",
    "    ExplainabilityAnalysisConfig,\n",
    "    ModelBiasMonitor,\n",
    "    ModelExplainabilityMonitor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context=predictor.endpoint_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bias_monitor = ModelBiasMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    max_runtime_in_seconds=1800,\n",
    ")\n",
    "\n",
    "model_bias_monitor_prefix = f'{prefix}/model-bias-output'\n",
    "model_bias_baselining_job_result_uri = f's3://{bucket}/{model_bias_monitor_prefix}/baseline'\n",
    "model_bias_s3_report_path = f's3://{bucket}/{model_bias_monitor_prefix}/reports'\n",
    "\n",
    "model_bias_data_config = DataConfig(\n",
    "    s3_data_input_path=val_data_s3,\n",
    "    s3_output_path=model_bias_baselining_job_result_uri,\n",
    "    label='Rings',\n",
    "    headers=columns,\n",
    "    dataset_type='text/csv',\n",
    ")\n",
    "\n",
    "model_bias_config = BiasConfig(\n",
    "    label_values_or_threshold=[df_train.Rings.median()],\n",
    "    facet_name='Sex',\n",
    "    facet_values_or_threshold=[0.0], # 0.0 represents Infant abalone\n",
    ")\n",
    "\n",
    "model_predicted_label_config = ModelPredictedLabelConfig()\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    model_name='abalone-xgb-2021-12-18-00-04-35-2021-12-29-23-42-52-509',\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    content_type='text/csv',\n",
    "    accept_type='text/csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bias_monitor.suggest_baseline(\n",
    "    model_config=model_config,\n",
    "    data_config=model_bias_data_config,\n",
    "    bias_config=model_bias_config,\n",
    "    model_predicted_label_config=model_predicted_label_config,\n",
    ")\n",
    "print(f'ModelBiasMonitor baselining job: {model_bias_monitor.latest_baselining_job_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_bias_constraints = model_bias_monitor.suggested_constraints()\n",
    "print()\n",
    "print(f\"ModelBiasMonitor suggested constraints: {model_bias_constraints.file_s3_uri}\")\n",
    "print(S3Downloader.read_file(model_bias_constraints.file_s3_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bias_analysis_config = None\n",
    "if not model_bias_monitor.latest_baselining_job:\n",
    "    model_bias_analysis_config = BiasAnalysisConfig(\n",
    "        model_bias_config,\n",
    "        headers=columns,\n",
    "        label='Rings',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model_bias_analysis_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bias_monitor.create_monitoring_schedule(\n",
    "    endpoint_input=endpointInput,\n",
    "    ground_truth_input=ground_truth_upload_path,\n",
    "    analysis_config=model_bias_analysis_config,\n",
    "    output_s3_uri=model_bias_s3_report_path,\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model explainability monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[columns_no_target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[df_train[columns_no_target].mean().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Sex'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[df_train['Sex'].mode()[0]]+\n",
    " df_train[columns_no_target[1:]].mean().tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can you choose good baselines? Often it is desirable to select a baseline with very low information content. For example, you can construct an average instance from the training dataset by taking either the median or average for numerical features and the mode for categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainability_monitor = ModelExplainabilityMonitor(\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    max_runtime_in_seconds=1800,\n",
    ")\n",
    "\n",
    "model_explainability_monitor_prefix = f'{prefix}/model-explainability-output'\n",
    "model_explainability_baselining_job_result_uri = f's3://{bucket}/{model_explainability_monitor_prefix}/baseline'\n",
    "model_explainability_s3_report_path = f's3://{bucket}/{model_explainability_monitor_prefix}/reports'\n",
    "\n",
    "model_explainability_data_config = DataConfig(\n",
    "    s3_data_input_path=val_data_s3,\n",
    "    s3_output_path=model_explainability_baselining_job_result_uri,\n",
    "    label='Rings',\n",
    "    headers=columns,\n",
    "    dataset_type='text/csv',\n",
    ")\n",
    "\n",
    "# Here use the mean value of test dataset as SHAP baseline\n",
    "shap_baseline = [df_train['Sex'].mode().tolist() + \n",
    "                 df_train[columns_no_target[1:]].mean().tolist()]\n",
    "\n",
    "shap_config = SHAPConfig(\n",
    "    baseline=shap_baseline,\n",
    "    num_samples=100, # val only has 418\n",
    "    agg_method='mean_abs',\n",
    "    save_local_shap_values=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainability_monitor.suggest_baseline(\n",
    "    data_config=model_explainability_data_config,\n",
    "    model_config=model_config,\n",
    "    explainability_config=shap_config,\n",
    ")\n",
    "print(f'ModelExplainabilityMonitor baselining job: {model_explainability_monitor.latest_baselining_job_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainability_monitor.latest_baselining_job.wait(logs=False)\n",
    "model_explainability_constraints = model_explainability_monitor.suggested_constraints()\n",
    "print()\n",
    "print(f'ModelExplainabilityMonitor suggested constraints: {model_explainability_constraints.file_s3_uri}')\n",
    "print(S3Downloader.read_file(model_explainability_constraints.file_s3_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_explainability_analysis_config = None\n",
    "if not model_explainability_monitor.latest_baselining_job:\n",
    "    # Remove label because only features are required for the analysis\n",
    "    model_explainability_analysis_config = ExplainabilityAnalysisConfig(\n",
    "        explainability_config=shap_config,\n",
    "        model_config=model_config,\n",
    "        headers=columns_no_target,\n",
    "    )\n",
    "    \n",
    "model_explainability_monitor.create_monitoring_schedule(\n",
    "    output_s3_uri=model_explainability_s3_report_path,\n",
    "    endpoint_input=endpoint_name,\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
