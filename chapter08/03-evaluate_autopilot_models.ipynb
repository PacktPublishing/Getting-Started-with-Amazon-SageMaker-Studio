{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket = session.default_bucket()\n",
    "prefix = 'sagemaker-studio-book/chapter08/winequality'\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import gmtime, strftime, sleep\n",
    "import json\n",
    "import io\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import AutoML\n",
    "automl = AutoML.attach(auto_ml_job_name='white-wine-predict-quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate name:  white-wine-predict-qualitysZ1CBE-003-1a47413b\n",
      "Objective metric name:  validation:f1\n",
      "Objective metric value:  0.4073199927806854\n",
      "\n",
      "\n",
      "Candidate name:  white-wine-predict-qualitysZ1CBE-093-c37343d7\n",
      "Objective metric name:  validation:f1\n",
      "Objective metric value:  0.4049299955368042\n",
      "\n",
      "\n",
      "Candidate name:  white-wine-predict-qualitysZ1CBE-082-6e1e3463\n",
      "Objective metric name:  validation:f1\n",
      "Objective metric value:  0.4048300087451935\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TOP_N_CANDIDATES = 3\n",
    "candidates = automl.list_candidates(sort_by='FinalObjectiveMetricValue',\n",
    "                                    sort_order='Descending',\n",
    "                                    max_results=TOP_N_CANDIDATES)\n",
    "\n",
    "for candidate in candidates:\n",
    "    print(\"Candidate name: \", candidate['CandidateName'])\n",
    "    print(\"Objective metric name: \", candidate['FinalAutoMLJobObjectiveMetric']['MetricName'])\n",
    "    print(\"Objective metric value: \", candidate['FinalAutoMLJobObjectiveMetric']['Value'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('winequality-white-test.csv')\n",
    "# test_data_no_target = ... # test_data to be used (without target column)\n",
    "test_file_basename = 'winequality-white-test-notarget.csv'\n",
    "test_file =  f's3://{bucket}/{prefix}/{test_file_basename}' # path of data to upload to S3 and perform batch inference (csv file of test_data_no_target)\n",
    "target_attribute_name = 'quality' # name of target column (values to predict)\n",
    "# target_attribute_values = np.sort(test_data[target_attribute_name].unique()).tolist() # list of unique values in target column (sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_response_keys = ['predicted_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up 3 Batch Transform Jobs in `transformers`\n"
     ]
    }
   ],
   "source": [
    "s3_transform_output_path = 's3://{}/{}/inference-results/'.format(bucket, prefix);\n",
    "\n",
    "transformers = []\n",
    "\n",
    "for candidate in candidates:\n",
    "    model = automl.create_model(name=candidate['CandidateName'],\n",
    "                                candidate=candidate,\n",
    "                                inference_response_keys=inference_response_keys)\n",
    "    \n",
    "    output_path = s3_transform_output_path + candidate['CandidateName'] +'/'\n",
    "    \n",
    "    transformers.append(\n",
    "        model.transformer(instance_count=1, \n",
    "                          instance_type='ml.m5.xlarge',\n",
    "                          assemble_with='Line',\n",
    "                          output_path=output_path))\n",
    "\n",
    "print(\"Setting up {} Batch Transform Jobs in `transformers`\".format(len(transformers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting transform job white-wine-predict-qualitysZ1CBE-003-1a-2021-06-29-00-22-07-845\n",
      "Starting transform job white-wine-predict-qualitysZ1CBE-093-c3-2021-06-29-00-22-08-294\n",
      "Starting transform job white-wine-predict-qualitysZ1CBE-082-6e-2021-06-29-00-22-10-787\n"
     ]
    }
   ],
   "source": [
    "for transformer in transformers:\n",
    "    transformer.transform(data=test_file, split_type='Line', \n",
    "                          content_type='text/csv', wait=False)\n",
    "    print(\"Starting transform job {}\".format(transformer._current_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 out of 3 transform jobs are running.\n",
      "3 out of 3 transform jobs are running.\n",
      "3 out of 3 transform jobs are running.\n",
      "3 out of 3 transform jobs are running.\n",
      "3 out of 3 transform jobs are running.\n",
      "3 out of 3 transform jobs are running.\n",
      "3 out of 3 transform jobs are running.\n",
      "3 out of 3 transform jobs are running.\n",
      "3 out of 3 transform jobs are running.\n",
      "3 out of 3 transform jobs are running.\n",
      "2 out of 3 transform jobs are running.\n",
      "0 out of 3 transform jobs are running.\n",
      "Transform job 'white-wine-predict-qualitysZ1CBE-003-1a-2021-06-29-00-22-07-845' finished with status Completed\n",
      "Transform job 'white-wine-predict-qualitysZ1CBE-093-c3-2021-06-29-00-22-08-294' finished with status Completed\n",
      "Transform job 'white-wine-predict-qualitysZ1CBE-082-6e-2021-06-29-00-22-10-787' finished with status Completed\n"
     ]
    }
   ],
   "source": [
    "pending_complete = True\n",
    "\n",
    "while pending_complete:\n",
    "    pending_complete = False\n",
    "    num_transform_jobs = len(transformers)\n",
    "    for transformer in transformers:\n",
    "        desc = sm.describe_transform_job(TransformJobName=transformer._current_job_name)\n",
    "        if desc['TransformJobStatus'] not in ['Failed', 'Completed']:\n",
    "            pending_complete = True\n",
    "        else:\n",
    "            num_transform_jobs -= 1\n",
    "    print(\"{} out of {} transform jobs are running.\".format(num_transform_jobs, len(transformers)))\n",
    "    sleep(30)\n",
    "    \n",
    "for transformer in transformers:\n",
    "    desc = sm.describe_transform_job(TransformJobName=transformer._current_job_name)\n",
    "    print(\"Transform job '{}' finished with status {}\".format(transformer._current_job_name, desc['TransformJobStatus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-552106442228/sagemaker-studio-book/chapter08/winequality/inference-results/white-wine-predict-qualitysZ1CBE-003-1a47413b/\n",
      "s3://sagemaker-us-west-2-552106442228/sagemaker-studio-book/chapter08/winequality/inference-results/white-wine-predict-qualitysZ1CBE-093-c37343d7/\n",
      "s3://sagemaker-us-west-2-552106442228/sagemaker-studio-book/chapter08/winequality/inference-results/white-wine-predict-qualitysZ1CBE-082-6e1e3463/\n"
     ]
    }
   ],
   "source": [
    "def get_csv_from_s3(s3uri, file_name):\n",
    "    parsed_url = urlparse(s3uri)\n",
    "    bucket_name = parsed_url.netloc\n",
    "    prefix = parsed_url.path[1:].strip('/')\n",
    "    s3 = boto3.resource('s3')\n",
    "    obj = s3.Object(bucket_name, '{}/{}'.format(prefix, file_name))\n",
    "    return obj.get()[\"Body\"].read().decode('utf-8')\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for transformer in transformers:\n",
    "    print(transformer.output_path)\n",
    "    pred_csv = get_csv_from_s3(transformer.output_path, \n",
    "                               '{}.out'.format(test_file_basename))\n",
    "    predictions.append(pd.read_csv(io.StringIO(pred_csv), header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = test_data[target_attribute_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate name:  white-wine-predict-qualitysZ1CBE-003-1a47413b\n",
      "Objective metric name:  validation:f1\n",
      "Objective metric value:  0.4073199927806854\n",
      "f1 = 0.51, Precision = 0.59 (macro)\n",
      "f1 = 0.67, Precision = 0.68 (weighted)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.70      0.39      0.50        18\n",
      "           5       0.63      0.67      0.65       144\n",
      "           6       0.67      0.77      0.72       215\n",
      "           7       0.76      0.57      0.65        94\n",
      "           8       0.78      0.44      0.56        16\n",
      "\n",
      "    accuracy                           0.67       490\n",
      "   macro avg       0.59      0.47      0.51       490\n",
      "weighted avg       0.68      0.67      0.67       490\n",
      "\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   7   8   3   0   0]\n",
      " [  0   2  96  45   1   0]\n",
      " [  0   1  37 166  10   1]\n",
      " [  0   0   8  31  54   1]\n",
      " [  0   0   0   3   6   7]]\n",
      "\n",
      "Candidate name:  white-wine-predict-qualitysZ1CBE-093-c37343d7\n",
      "Objective metric name:  validation:f1\n",
      "Objective metric value:  0.4049299955368042\n",
      "f1 = 0.53, Precision = 0.63 (macro)\n",
      "f1 = 0.70, Precision = 0.71 (weighted)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.86      0.33      0.48        18\n",
      "           5       0.69      0.69      0.69       144\n",
      "           6       0.69      0.81      0.74       215\n",
      "           7       0.78      0.65      0.71        94\n",
      "           8       0.78      0.44      0.56        16\n",
      "\n",
      "    accuracy                           0.71       490\n",
      "   macro avg       0.63      0.49      0.53       490\n",
      "weighted avg       0.71      0.71      0.70       490\n",
      "\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   6   8   4   0   0]\n",
      " [  0   1  99  43   1   0]\n",
      " [  0   0  28 174  12   1]\n",
      " [  0   0   5  27  61   1]\n",
      " [  0   0   0   5   4   7]]\n",
      "\n",
      "Candidate name:  white-wine-predict-qualitysZ1CBE-082-6e1e3463\n",
      "Objective metric name:  validation:f1\n",
      "Objective metric value:  0.4048300087451935\n",
      "f1 = 0.53, Precision = 0.65 (macro)\n",
      "f1 = 0.70, Precision = 0.72 (weighted)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.86      0.33      0.48        18\n",
      "           5       0.70      0.68      0.69       144\n",
      "           6       0.69      0.83      0.75       215\n",
      "           7       0.77      0.64      0.70        94\n",
      "           8       0.88      0.44      0.58        16\n",
      "\n",
      "    accuracy                           0.71       490\n",
      "   macro avg       0.65      0.49      0.53       490\n",
      "weighted avg       0.72      0.71      0.70       490\n",
      "\n",
      "[[  0   0   3   0   0   0]\n",
      " [  0   6   9   3   0   0]\n",
      " [  0   1  98  44   1   0]\n",
      " [  0   0  25 178  12   0]\n",
      " [  0   0   5  28  60   1]\n",
      " [  0   0   0   4   5   7]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for prediction, candidate in zip(predictions, candidates):\n",
    "    print(\"Candidate name: \", candidate['CandidateName'])\n",
    "    print(\"Objective metric name: \", candidate['FinalAutoMLJobObjectiveMetric']['MetricName'])\n",
    "    print(\"Objective metric value: \", candidate['FinalAutoMLJobObjectiveMetric']['Value'])\n",
    "\n",
    "    scores={}\n",
    "    for avg in ['macro', 'weighted']:\n",
    "        scores[avg] = [f1_score(labels, prediction, average=avg), \n",
    "                       precision_score(labels, prediction, average=avg)]\n",
    "        print('f1 = %.2f, Precision = %.2f (%s)' % (scores[avg][0], scores[avg][1], avg))\n",
    "    print(classification_report(labels, prediction))\n",
    "    print(confusion_matrix(labels, prediction))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
