{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'sagemaker-studio-book/chapter07'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n",
      "x_train shape: (25000,)\n",
      "x_test shape: (25000, 400)\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 400\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "csv_test_dir_prefix = 'imdb_data/test'\n",
    "csv_test_filename = 'test.csv'\n",
    "csv_test_dir = os.path.join(os.getcwd(), csv_test_dir_prefix)\n",
    "os.makedirs(csv_test_dir, exist_ok=True)\n",
    "\n",
    "np.savetxt(os.path.join(csv_test_dir, csv_test_filename), \n",
    "           np.array(x_test, dtype=np.int32), fmt='%d', delimiter=\",\")\n",
    "\n",
    "test_data_s3prefix = f'{prefix}/data/csv_test'\n",
    "test_data_s3 = sagemaker.Session().upload_data(path=csv_test_dir, \n",
    "                                               key_prefix=test_data_s3prefix)\n",
    "print(test_data_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "training_job_name='imdb-tf-2021-09-21-17-37-20'\n",
    "\n",
    "attached_estimator = TensorFlow.attach(training_job_name)\n",
    "attached_estimator.logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transformer = attached_estimator.transformer(instance_count=1, \n",
    "                                             instance_type='ml.c5.xlarge')\n",
    "\n",
    "transformer.transform(test_data_s3, content_type='text/csv')\n",
    "print('Waiting for transform job: ' + transformer.latest_transform_job.job_name)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = transformer.output_path\n",
    "output_prefix = 'imdb_data/test_output'\n",
    "!mkdir -p {output_prefix}\n",
    "!aws s3 cp --recursive {output} {output_prefix}\n",
    "\n",
    "with open(f'{output_prefix}/csv-test.csv.out', 'r') as f:\n",
    "    jstr = json.load(f)\n",
    "    results = [float('%.3f'%(item)) for sublist in jstr['predictions'] \n",
    "                                    for item in sublist]\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(score):\n",
    "    return 'positive' if score > 0.5 else 'negative' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"please give this one a miss br br kristy swanson and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite lacklustre so all you madison fans give this a miss\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "regex = re.compile(r'^[\\?\\s]+')\n",
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i watched this movie purely for the setting it was filmed in an old hotel that a friend owns shares of the plot was predictable the acting was ? at best the scares were all gross outs not true scares br br i don't remember much of the plot and i think that's because there wasn't much of one to remember they didn't even use the hotel to it's fullest potential the beaches are fantastic and the hotel is situated on a ? at low tide you can walk almost 1 4 mile into the bay which is actually an eerie sight first thing in the morning or late at night when the wind is howling through the cracks br br the best way to see this movie is with the remote in your hand so you can fast forward through the action and i'm using that term ? scenes and pause at the beauty of the surroundings\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_index=199\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "first_decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') \n",
    "                                 for i in x_test[data_index]])\n",
    "regex.sub('', first_decoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled sentiment for this review is negative\n",
      "Predicted sentiment is negative\n"
     ]
    }
   ],
   "source": [
    "print(f'Labeled sentiment for this review is {get_sentiment(y_test[data_index])}')\n",
    "print(f'Predicted sentiment is {get_sentiment(results[data_index])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
