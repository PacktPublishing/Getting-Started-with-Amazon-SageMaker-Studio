{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is developed using the `Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)` kernel on an `ml.t3.medium` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q sagemaker-experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'sagemaker-studio-book/chapter07'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 400\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "csv_test_dir_prefix = 'imdb_data/test'\n",
    "csv_test_filename = 'test.csv'\n",
    "csv_test_dir = os.path.join(os.getcwd(), csv_test_dir_prefix)\n",
    "os.makedirs(csv_test_dir, exist_ok=True)\n",
    "\n",
    "np.savetxt(os.path.join(csv_test_dir, csv_test_filename), \n",
    "           np.array(x_test, dtype=np.int32), fmt='%d', delimiter=\",\")\n",
    "\n",
    "test_data_s3prefix = f'{prefix}/data/csv_test'\n",
    "test_data_s3 = sess.upload_data(path=csv_test_dir, \n",
    "                                key_prefix=test_data_s3prefix)\n",
    "print(test_data_s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "# insert the training job name from chapter05/02-tensorflow_sentiment_analysis.ipynb\n",
    "training_job_name= '<your-training-job-name>' # e.g. imdb-tf-2022-02-18-05-31-26\n",
    "\n",
    "estimator = TensorFlow.attach(training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from botocore.exceptions import ClientError\n",
    "from time import gmtime, strftime\n",
    "\n",
    "experiment_name = 'imdb-sentiment-analysis'\n",
    "\n",
    "exp_datetime = strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n",
    "jobname = f'imdb-tf-bt-{exp_datetime}'\n",
    "\n",
    "# Creating a new trial for the experiment\n",
    "exp_trial = Trial.load(trial_name=training_job_name)\n",
    "\n",
    "experiment_config={\n",
    "    'ExperimentName': experiment_name,\n",
    "    'TrialName': exp_trial.trial_name,\n",
    "    'TrialComponentDisplayName': 'Inference-BatchTransform'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_datetime = strftime('%Y-%m-%d-%H-%M-%S', gmtime())\n",
    "jobname = f'imdb-tf-bt-{exp_datetime}'\n",
    "\n",
    "s3_output_location = f's3://{bucket}/{prefix}/{jobname}'\n",
    "\n",
    "transformer = estimator.transformer(instance_count=1, \n",
    "                                    instance_type='ml.c5.xlarge',\n",
    "                                    max_payload = 2, # MB\n",
    "                                    accept = 'application/jsonlines',\n",
    "                                    output_path = s3_output_location,\n",
    "                                    assemble_with = 'Line')\n",
    "\n",
    "transformer.transform(test_data_s3, \n",
    "                      content_type='text/csv', \n",
    "                      split_type = 'Line', \n",
    "                      job_name = jobname,\n",
    "                      experiment_config = experiment_config)\n",
    "print('Waiting for transform job: ' + transformer.latest_transform_job.job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = transformer.output_path\n",
    "output_prefix = 'imdb_data/test_output'\n",
    "!mkdir -p {output_prefix}\n",
    "!aws s3 cp --recursive {output} {output_prefix}\n",
    "!head {output_prefix}/{csv_test_filename}.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results=[]\n",
    "with open(f'{output_prefix}/{csv_test_filename}.out', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        print(line)\n",
    "        json_output = json.loads(line)\n",
    "        result = [float('%.3f'%(item)) for sublist in json_output['predictions'] \n",
    "                                       for item in sublist]\n",
    "        results += result\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(score):\n",
    "    return 'positive' if score > 0.5 else 'negative' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regex = re.compile(r'^[\\?\\s]+')\n",
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index=199\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "first_decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') \n",
    "                                 for i in x_test[data_index]])\n",
    "regex.sub('', first_decoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Labeled sentiment for this review is {get_sentiment(y_test[data_index])}')\n",
    "print(f'Predicted sentiment is {get_sentiment(results[data_index])}')"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
