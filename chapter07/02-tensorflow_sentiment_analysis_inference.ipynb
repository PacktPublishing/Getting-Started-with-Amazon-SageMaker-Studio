{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is developed using the `Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)` kernel on an `ml.t3.medium` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'sagemaker-studio-book/chapter07'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.python.keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_test_dir_prefix = 'imdb_data/test'\n",
    "csv_test_filename = 'test.csv'\n",
    "\n",
    "x_test = np.loadtxt(f'{csv_test_dir_prefix}/{csv_test_filename}', \n",
    "                    delimiter=',', dtype='int')\n",
    "\n",
    "print('x_test shape:', x_test.shape)\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 400\n",
    "\n",
    "_ , (_, y_test) = imdb.load_data(num_words=max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "# insert the training job name from chapter05/02-tensorflow_sentiment_analysis.ipynb\n",
    "training_job_name= '<your-training-job-name>' # e.g. imdb-tf-2022-02-18-05-31-26\n",
    "\n",
    "estimator = TensorFlow.attach(training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, \n",
    "                             instance_type='ml.c5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index=199"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=predictor.predict(x_test[data_index])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(score):\n",
    "    return 'positive' if score > 0.5 else 'negative' \n",
    "\n",
    "import re\n",
    "\n",
    "regex = re.compile(r'^[\\?\\s]+')\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "first_decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') \n",
    "                                 for i in x_test[data_index]])\n",
    "regex.sub('', first_decoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Labeled sentiment for this review is {get_sentiment(y_test[data_index])}')\n",
    "print(f'Predicted sentiment is {get_sentiment(prediction[\"predictions\"][0][0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictor.predict(x_test[:5000]) # this would throw an error due to large volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = sess.boto_session.client('sagemaker')\n",
    "autoscaling_client = sess.boto_session.client('application-autoscaling')\n",
    "\n",
    "endpoint_name = predictor.endpoint_name\n",
    "response = sagemaker_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# application autoscaling references the endpoint using string below\n",
    "resource_id=f'endpoint/{endpoint_name}/variant/AllTraffic' \n",
    "response = autoscaling_client.register_scalable_target(\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    MinCapacity=1,\n",
    "    MaxCapacity=4\n",
    ")\n",
    "\n",
    "response = autoscaling_client.put_scaling_policy(\n",
    "    PolicyName='Invocations-ScalingPolicy',\n",
    "    ServiceNamespace='sagemaker', # The namespace of the AWS service that provides the resource. \n",
    "    ResourceId=resource_id, # Endpoint name \n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    PolicyType='TargetTrackingScaling', # Other options are 'StepScaling'|'TargetTrackingScaling'\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        'TargetValue': 4000.0, # The target value for the metric below.\n",
    "        'PredefinedMetricSpecification': {\n",
    "            'PredefinedMetricType': 'SageMakerVariantInvocationsPerInstance', \n",
    "        },\n",
    "        'ScaleInCooldown': 600, \n",
    "        'ScaleOutCooldown': 300,\n",
    "        'DisableScaleIn': False # If true, scale-in is disabled.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = autoscaling_client.describe_scaling_policies(\n",
    "    ServiceNamespace='sagemaker'\n",
    ")\n",
    "\n",
    "for i in response['ScalingPolicies']:\n",
    "    print('')\n",
    "    print(i['PolicyName'])\n",
    "    print('')\n",
    "    if('TargetTrackingScalingPolicyConfiguration' in i):\n",
    "        print(i['TargetTrackingScalingPolicyConfiguration']) \n",
    "    else:\n",
    "        print(i['StepScalingPolicyConfiguration'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You reach the end of this example. Typically it's recommended to delete the endpoint to stop incurring cost. However, the endpoint deployed in this notebook will be used again in [04-load_testing.ipynb](./04-load_testing.ipynb), so deletion is optional when you will soon advance to [04-load_testing.ipynb](./04-load_testing.ipynb).\n",
    "\n",
    "If you decide to use the endpoint for [04-load_testing.ipynb](./04-load_testing.ipynb), you need the endpoint name later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
