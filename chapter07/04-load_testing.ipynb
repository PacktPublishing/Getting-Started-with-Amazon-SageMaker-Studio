{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install locust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'sagemaker-studio-book/chapter07'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir load_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile load_testing/locustfile.py\n",
    "from locust import task, between, events, User\n",
    "import sagemaker\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "import json\n",
    "import os, sys\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "endpoint_name=os.environ['ENDPOINT_NAME']\n",
    "predictor = sagemaker.predictor.Predictor(endpoint_name, \n",
    "                    serializer=JSONSerializer(),\n",
    "                    deserializer=JSONDeserializer())\n",
    "print(predictor.endpoint_name)\n",
    "\n",
    "csv_test_dir_prefix = 'imdb_data/test'\n",
    "csv_test_filename = 'test.csv'\n",
    "\n",
    "# loads a sample and make one inference call\n",
    "x_test = np.loadtxt(f'{csv_test_dir_prefix}/{csv_test_filename}', \n",
    "                    delimiter=',', dtype='int', max_rows=1)\n",
    "out = predictor.predict(x_test)\n",
    "print(out)\n",
    "\n",
    "class SMLoadTestUser(User):\n",
    "    wait_time = between(0, 1)\n",
    "    \n",
    "    @task\n",
    "    def test_endpoint(self):\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            predictor.predict(x_test)\n",
    "            total_time = int((time.time() - start_time) * 1000)\n",
    "            events.request_success.fire(\n",
    "                request_type=\"sagemaker\",\n",
    "                name=\"predict\",\n",
    "                response_time=total_time,\n",
    "                response_length=0)\n",
    "\n",
    "        except:\n",
    "            total_time = int((time.time() - start_time) * 1000)\n",
    "            events.request_failure.fire(\n",
    "                request_type=\"sagemaker\",\n",
    "                name=\"predict\",\n",
    "                response_time=total_time,\n",
    "                response_length=0,\n",
    "                exception=sys.exc_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1: load testing original instance configuration (one ml.c5.xlarge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = sess.boto_session.client('sagemaker')\n",
    "autoscaling_client = sess.boto_session.client('application-autoscaling')\n",
    "\n",
    "endpoint_name = 'imdb-tf-2021-09-21-17-37-20-2021-10-04-21-28-40-974'\n",
    "resource_id = f'endpoint/{endpoint_name}/variant/AllTraffic' \n",
    "response = autoscaling_client.register_scalable_target(\n",
    "   ServiceNamespace='sagemaker',\n",
    "   ResourceId=resource_id,\n",
    "   ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "   MinCapacity=1,\n",
    "   MaxCapacity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "export ENDPOINT_NAME='imdb-tf-2021-09-21-17-37-20-2021-10-04-21-28-40-974'\n",
    "locust -f load_testing/locustfile.py --worker --loglevel ERROR --autostart --autoquit 10 & \n",
    "\n",
    "locust -f load_testing/locustfile.py --worker --loglevel ERROR --autostart --autoquit 10 &\n",
    "\n",
    "locust -f load_testing/locustfile.py --headless -u 500 -r 10 -t 60s \\\n",
    "       --print-stats --only-summary --loglevel ERROR \\\n",
    "       --autostart --autoquit 10 --master --expect-workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 2: load test scaled up configuration (one ml.c5.2xlarge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "import json\n",
    "import os, sys\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "training_job_name='imdb-tf-2021-09-21-17-37-20'\n",
    "\n",
    "estimator = TensorFlow.attach(training_job_name)\n",
    "predictor_c5_2xl = estimator.deploy(initial_instance_count=1, \n",
    "                                      instance_type='ml.c5.2xlarge',\n",
    "                                      wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_c5_2xl.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "export ENDPOINT_NAME='imdb-tf-2021-09-21-17-37-20-2021-10-11-16-01-55-197'\n",
    "locust -f load_testing/locustfile.py --worker --loglevel ERROR --autostart --autoquit 10 & \n",
    "\n",
    "locust -f load_testing/locustfile.py --worker --loglevel ERROR --autostart --autoquit 10 &\n",
    "\n",
    "locust -f load_testing/locustfile.py --headless -u 500 -r 10 -t 60s \\\n",
    "       --print-stats --only-summary --loglevel ERROR \\\n",
    "       --autostart --autoquit 10 --master --expect-workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 3: load test GPU instance dedicated to ML inference (one ml.g4dn.xlarge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_g4dn_xl = estimator.deploy(initial_instance_count=1, \n",
    "                                      instance_type='ml.g4dn.xlarge',\n",
    "                                      wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_g4dn_xl.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "export ENDPOINT_NAME='imdb-tf-2021-09-21-17-37-20-2021-10-11-16-36-47-266'\n",
    "locust -f load_testing/locustfile.py --worker --loglevel ERROR --autostart --autoquit 10 & \n",
    "\n",
    "locust -f load_testing/locustfile.py --worker --loglevel ERROR --autostart --autoquit 10 &\n",
    "\n",
    "locust -f load_testing/locustfile.py --headless -u 500 -r 10 -t 60s \\\n",
    "       --print-stats --only-summary --loglevel ERROR \\\n",
    "       --autostart --autoquit 10 --master --expect-workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 4: load test autoscaling (1-4 ml.c5.xlarge instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = 'imdb-tf-2021-09-21-17-37-20-2021-10-04-21-28-40-974'\n",
    "resource_id=f'endpoint/{endpoint_name}/variant/AllTraffic' # This is the format in which application autoscaling references the endpoint\n",
    "\n",
    "response = autoscaling_client.register_scalable_target(\n",
    "    ServiceNamespace='sagemaker',\n",
    "    ResourceId=resource_id,\n",
    "    ScalableDimension='sagemaker:variant:DesiredInstanceCount',\n",
    "    MinCapacity=1,\n",
    "    MaxCapacity=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = autoscaling_client.describe_scaling_policies(\n",
    "    ServiceNamespace='sagemaker'\n",
    ")\n",
    "# print(response)\n",
    "for i in response['ScalingPolicies']:\n",
    "    print('')\n",
    "    print(i['PolicyName'])\n",
    "    print('')\n",
    "    if('TargetTrackingScalingPolicyConfiguration' in i):\n",
    "        print(i['TargetTrackingScalingPolicyConfiguration']) \n",
    "    else:\n",
    "        print(i['StepScalingPolicyConfiguration'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "export ENDPOINT_NAME='imdb-tf-2021-09-21-17-37-20-2021-10-04-21-28-40-974'\n",
    "locust -f load_testing/locustfile.py --worker --loglevel ERROR --autostart --autoquit 10 & \n",
    "\n",
    "locust -f load_testing/locustfile.py --worker --loglevel ERROR --autostart --autoquit 10 &\n",
    "\n",
    "locust -f load_testing/locustfile.py --headless -u 500 -r 10 -t 600s \\\n",
    "       --print-stats --only-summary --loglevel ERROR \\\n",
    "       --autostart --autoquit 10 --master --expect-workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the next cell to delete endpoints to stop incurring cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor_g4dn_xl.delete_endpoint()\n",
    "# predictor_c5_2xl.delete_endpoint()\n",
    "# predictor_g4dn_xl.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
